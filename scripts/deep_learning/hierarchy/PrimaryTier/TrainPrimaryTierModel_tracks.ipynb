{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227c278e",
   "metadata": {},
   "source": [
    "## Train Primary Track Networks\n",
    "\n",
    "written by Isobel Mawby (i.mawby1@lancaster.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71da499",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Imports\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.getcwd()[0:len(os.getcwd()) - 11])\n",
    "sys.path.insert(1, os.getcwd()[0:len(os.getcwd()) - 11] + '/Metrics')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "\n",
    "import Models\n",
    "import Datasets\n",
    "import TrainingMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165152e5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Put the path to the primary track training file (created by WritePrimaryTierFile.ipynb with isTrackMode == True) and set ouput file names\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b068f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFileName = sys.path[0] + '/files/hierarchy_TRAIN_track.npz'\n",
    "branchModelPath = sys.path[0] + '/models/primary_track_branch_model'\n",
    "classifierModelPath = sys.path[0] + '/models/primary_track_classifier_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632d44d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Set hyperparameters\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdabffa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Get data from file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(trainFileName)\n",
    "\n",
    "# Variables\n",
    "variables_train = data['variables_train']\n",
    "variables_test = data['variables_test']\n",
    "# Training cut\n",
    "trainingCutDCA_train = data['trainingCutDCA_train']\n",
    "trainingCutDCA_test = data['trainingCutDCA_test']\n",
    "# Truth\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "isTruePrimaryLink_train = data['isTruePrimaryLink_train']\n",
    "isTruePrimaryLink_test = data['isTruePrimaryLink_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c7fd3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Set multiplicity variables\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nVariables = variables_train.shape[1]\n",
    "nLinks = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd666db",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Check shapes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b511a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('variables_train.shape:', variables_train.shape)\n",
    "print('variables_test.shape:', variables_test.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('y_test.shape:', y_test.shape)\n",
    "print('trainingCutDCA_train.shape:', trainingCutDCA_train.shape)\n",
    "print('trainingCutDCA_test.shape:', trainingCutDCA_test.shape)\n",
    "print('isTruePrimaryLink_train.shape:', isTruePrimaryLink_train.shape)\n",
    "print('isTruePrimaryLink_test.shape:', isTruePrimaryLink_test.shape)\n",
    "print('')\n",
    "print('ntrain:', variables_train.shape[0])\n",
    "print('ntest:', variables_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63c16f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Apply training cut mask\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4874eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training cut threshold\n",
    "MAX_TRAINING_CUT_DCA = 50.0\n",
    "\n",
    "######################\n",
    "# training set first\n",
    "######################\n",
    "# Make mask\n",
    "passTrainingCutDCA_train = trainingCutDCA_train < MAX_TRAINING_CUT_DCA\n",
    "passTrainingCuts_train = passTrainingCutDCA_train\n",
    "\n",
    "# Mask the 1D variables... shape=(nEntries, )\n",
    "isTruePrimaryLink_train = isTruePrimaryLink_train[passTrainingCuts_train]\n",
    "\n",
    "# Mask the truth... shape=(nEntries, nLinks)\n",
    "y_train = y_train[np.column_stack([passTrainingCuts_train] * nLinks)].reshape(-1, nLinks)\n",
    "\n",
    "# Mask the variable... shape=(nEntries, nVariables)\n",
    "variables_train = variables_train[[[entry] * nVariables for entry in passTrainingCuts_train]].reshape(-1, nVariables)\n",
    "\n",
    "######################\n",
    "# now test set\n",
    "######################\n",
    "# Make mask\n",
    "passTrainingCutDCA_test = trainingCutDCA_test < MAX_TRAINING_CUT_DCA\n",
    "passTrainingCuts_test = passTrainingCutDCA_test\n",
    "\n",
    "# Mask the 1D variables... shape=(nEntries, )\n",
    "isTruePrimaryLink_test = isTruePrimaryLink_test[passTrainingCuts_test]\n",
    "\n",
    "# Mask the truth... shape=(nEntries, nLinks)\n",
    "y_test = y_test[np.column_stack([passTrainingCuts_test] * nLinks)].reshape(-1, nLinks)\n",
    "\n",
    "# Mask the variable... shape=(nEntries, nVariables)\n",
    "variables_test = variables_test[[[entry] * nVariables for entry in passTrainingCuts_test]].reshape(-1, nVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf7d8c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Check shapes after training cut application\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c59a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('variables_train.shape:', variables_train.shape)\n",
    "print('variables_test.shape:', variables_test.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('y_test.shape:', y_test.shape)\n",
    "print('isTruePrimaryLink_train.shape:', isTruePrimaryLink_train.shape)\n",
    "print('isTruePrimaryLink_test.shape:', isTruePrimaryLink_test.shape)\n",
    "print('')\n",
    "print('ntrain:', variables_train.shape[0])\n",
    "print('ntest:', variables_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adcf12",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Define class weights for branch model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrue = np.count_nonzero(y_train == 1)\n",
    "nBackground = np.count_nonzero(y_train == 0)\n",
    "nWrongOrientation = np.count_nonzero(y_train == 2)\n",
    "maxLinks = max(nTrue, nBackground, nWrongOrientation)\n",
    "\n",
    "classWeights_branch = torch.tensor([float(maxLinks)/float(nBackground), float(maxLinks)/float(nTrue), float(maxLinks)/float(nWrongOrientation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93d637c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Define class weights for classifier model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17412249",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_true_primary_train = np.count_nonzero(isTruePrimaryLink_train == True)\n",
    "n_false_primary_train = np.count_nonzero(isTruePrimaryLink_train == False)\n",
    "\n",
    "maxCounts_train = max(n_true_primary_train, n_false_primary_train)\n",
    "\n",
    "classWeights_classifier = {'true_primary_train'  : maxCounts_train/n_true_primary_train, \\\n",
    "                           'false_primary_train' : maxCounts_train/n_false_primary_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f14a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Build the training input for each edge. This is a concatenation of the variable tensor of this edge and those of all other edges, such that the variables for the edge in question are first.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abc6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_model_input_train = Models.PrepareBranchModelInput(nLinks, Models.primary_tier_n_orientation_indep_vars, Models.primary_tier_n_orientation_dep_vars, variables_train)\n",
    "branch_model_input_test = Models.PrepareBranchModelInput(nLinks, Models.primary_tier_n_orientation_indep_vars, Models.primary_tier_n_orientation_dep_vars, variables_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a2631",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Prepare Dataset objects\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799290b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Datasets.TwoEdgeDataset(branch_model_input_train[0], branch_model_input_train[1], y_train[:,0], y_train[:,1], isTruePrimaryLink_train, np.zeros(isTruePrimaryLink_train.shape))\n",
    "loader_train = Datasets.DataLoader(dataset_train, shuffle=True, batch_size=BATCH_SIZE)    \n",
    "\n",
    "dataset_test = Datasets.TwoEdgeDataset(branch_model_input_test[0], branch_model_input_test[1], y_test[:,0], y_test[:,1], isTruePrimaryLink_test, np.zeros(isTruePrimaryLink_test.shape))\n",
    "loader_test = Datasets.DataLoader(dataset_test, shuffle=True, batch_size=BATCH_SIZE)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4687329",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Define branch and classifier models\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_model = Models.OrientationModel(nVariables, dropoutRate=DROPOUT_RATE)\n",
    "classifier_model = Models.ClassifierModel(nLinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95917e0a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Define loss functions for training to implement custom weighting\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_branch(pred, target, classWeights) :\n",
    "    loss_func = torch.nn.CrossEntropyLoss(weight=classWeights)\n",
    "    loss = loss_func(pred, target)    \n",
    "    return loss\n",
    "\n",
    "def loss_function_classifier(pred, target, classWeights) :\n",
    "    # Do weighting\n",
    "    weight = torch.ones(target.shape)\n",
    "    weight[target < 0.5] = classWeights['false_primary_train']\n",
    "    weight[target > 0.5] = classWeights['true_primary_train']\n",
    "    \n",
    "    # Use BCE loss\n",
    "    loss_func = torch.nn.BCELoss(weight=weight)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = loss_func(pred, target)    \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73bd9e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Training/validation loop functions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac77df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunTrainingLoop(nLinks, dataset_batch, branch_model, classifier_model, classWeights_branch, classWeights_classifier) : \n",
    "    classifier_input = torch.empty(0,)\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in range(nLinks) :\n",
    "        edge_name = \"edge\" + str(i)\n",
    "        pred = branch_model(dataset_batch[edge_name][0])\n",
    "        total_loss += loss_function_branch(pred, dataset_batch[edge_name][1], classWeights_branch) \n",
    "        classifier_input = torch.concatenate((classifier_input, pred), axis=1)\n",
    "\n",
    "    classifier_target = dataset_batch[\"truth_link\"].reshape(-1,1)\n",
    "    classifier_pred = classifier_model(classifier_input)  \n",
    "    total_loss += loss_function_classifier(classifier_pred, classifier_target, classWeights_classifier)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def RunValidationLoop(nLinks, dataset_batch, branch_model, classifier_model, classWeights_branch, classWeights_classifier, linkMetrics) : \n",
    "    classifier_input = torch.empty(0,)\n",
    "    \n",
    "    for i in range(nLinks) :\n",
    "        edge_name = \"edge\" + str(i)\n",
    "        pred = branch_model(dataset_batch[edge_name][0])\n",
    "        branch_loss = loss_function_branch(pred, dataset_batch[edge_name][1], classWeights_branch) \n",
    "        linkMetrics.edge_metrics[i].Fill(branch_loss, pred, dataset_batch[edge_name][1])      \n",
    "        classifier_input = torch.concatenate((classifier_input, pred), axis=1)\n",
    "\n",
    "    classifier_target = dataset_batch[\"truth_link\"].reshape(-1,1)\n",
    "    classifier_pred = classifier_model(classifier_input) \n",
    "    classifier_loss = loss_function_classifier(classifier_pred, classifier_target, classWeights_classifier)\n",
    "    linkMetrics.classifier_metrics.Fill(classifier_loss, classifier_pred, classifier_target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da342af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Training/testing loops\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788d735",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimiser\n",
    "optimiser = torch.optim.Adam(itertools.chain(branch_model.parameters(), classifier_model.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "# Put here some metrics\n",
    "epochs_metrics = []\n",
    "training_link_metrics = []\n",
    "testing_link_metrics = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    # Begin training mode\n",
    "    branch_model.train()\n",
    "    classifier_model.train()\n",
    "    \n",
    "    for dataset_batch in loader_train:  \n",
    "        \n",
    "        # Skip incomplete batches\n",
    "        if (dataset_batch[\"truth_link\"].shape[0] != BATCH_SIZE) :\n",
    "            continue           \n",
    "            \n",
    "        # Run training loop\n",
    "        total_loss = RunTrainingLoop(nLinks, dataset_batch, branch_model, classifier_model, classWeights_branch, classWeights_classifier)\n",
    "            \n",
    "        # Update model parameters\n",
    "        optimiser.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Begin testing mode\n",
    "        branch_model.eval()\n",
    "        classifier_model.eval()\n",
    "        \n",
    "        # Initialise metrics        \n",
    "        linkMetrics_train = TrainingMetrics.LinkMetrics(nLinks)\n",
    "        linkMetrics_test = TrainingMetrics.LinkMetrics(nLinks)\n",
    "                \n",
    "        for dataset_batch_train in loader_train:  \n",
    "\n",
    "            # Skip incomplete batches\n",
    "            if (dataset_batch_train[\"truth_link\"].shape[0] != BATCH_SIZE) :\n",
    "                continue \n",
    "                \n",
    "            # Run validation loop\n",
    "            RunValidationLoop(nLinks, dataset_batch_train, branch_model, classifier_model, classWeights_branch, classWeights_classifier, linkMetrics_train)\n",
    "            \n",
    "        for dataset_batch_test in loader_test:  \n",
    "\n",
    "            # Skip incomplete batches\n",
    "            if (dataset_batch_test[\"truth_link\"].shape[0] != BATCH_SIZE) :\n",
    "                continue\n",
    "                \n",
    "            # Run validation loop\n",
    "            RunValidationLoop(nLinks, dataset_batch_test, branch_model, classifier_model, classWeights_branch, classWeights_classifier, linkMetrics_test)            \n",
    "\n",
    "        epochs_metrics.append(epoch)                    \n",
    "    \n",
    "    ##########################\n",
    "    # Calc metrics for epoch \n",
    "    ##########################   \n",
    "    # Find threshold\n",
    "    optimal_threshold_train, maximum_accuracy_train = TrainingMetrics.calculate_accuracy(linkMetrics_train)\n",
    "    optimal_threshold_test, maximum_accuracy_test = TrainingMetrics.calculate_accuracy(linkMetrics_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    linkMetrics_train.Evaluate(optimal_threshold_train)\n",
    "    linkMetrics_test.Evaluate(optimal_threshold_test)\n",
    "    \n",
    "    # Add to our lists\n",
    "    training_link_metrics.append(linkMetrics_train)\n",
    "    testing_link_metrics.append(linkMetrics_test) \n",
    "    \n",
    "    # Do some prints\n",
    "    print('----------------------------------------')\n",
    "    print('Epoch:', epoch)\n",
    "    print('----------------------------------------')\n",
    "    print('training_classification_loss:', round(linkMetrics_train.classifier_metrics.av_loss, 2))\n",
    "    print('----')\n",
    "    print('optimal_threshold_train:', optimal_threshold_train)\n",
    "    print('accuracy_train:', str(round(maximum_accuracy_train.item(), 2)) +'%')\n",
    "    print('positive_as_positive_fraction_train:', str(round(linkMetrics_train.classifier_metrics.pos_as_pos_frac * 100.0, 2)) + '%')\n",
    "    print('positive_as_negative_fraction_train:', str(round(linkMetrics_train.classifier_metrics.pos_as_neg_frac * 100.0, 2)) + '%')\n",
    "    print('negative_as_negative_fraction_train:', str(round(linkMetrics_train.classifier_metrics.neg_as_pos_frac * 100.0, 2)) + '%')\n",
    "    print('negative_as_positive_fraction_train:', str(round(linkMetrics_train.classifier_metrics.neg_as_neg_frac * 100.0, 2)) + '%')\n",
    "    print('----')\n",
    "    print('testing_classification_loss:', round(linkMetrics_test.classifier_metrics.av_loss, 2))\n",
    "    print('----')\n",
    "    print('optimal_threshold_test:', optimal_threshold_test)\n",
    "    print('accuracy_test:', str(round(maximum_accuracy_test.item(), 2)) +'%')\n",
    "    print('positive_as_positive_fraction_test:', str(round(linkMetrics_test.classifier_metrics.pos_as_pos_frac * 100.0, 2)) + '%')\n",
    "    print('positive_as_negative_fraction_test:', str(round(linkMetrics_test.classifier_metrics.pos_as_neg_frac * 100.0, 2)) + '%')\n",
    "    print('negative_as_negative_fraction_test:', str(round(linkMetrics_test.classifier_metrics.neg_as_pos_frac * 100.0, 2)) + '%')\n",
    "    print('negative_as_positive_fraction_test:', str(round(linkMetrics_test.classifier_metrics.neg_as_neg_frac * 100.0, 2)) + '%')\n",
    "    print('----')\n",
    "    \n",
    "    for i in [0, 1, 2] :\n",
    "        TrainingMetrics.plot_scores_branch(linkMetrics_train, linkMetrics_test, 0, i)\n",
    "\n",
    "    TrainingMetrics.plot_scores_classifier(linkMetrics_train, linkMetrics_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e6bf6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Plot metrics associated with training \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a40a74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TrainingMetrics.plot_branch_loss_evolution(epochs_metrics, training_link_metrics, testing_link_metrics, 0, 'Loss - branch_model_0')\n",
    "TrainingMetrics.plot_branch_loss_evolution(epochs_metrics, training_link_metrics, testing_link_metrics, 1, 'Loss - branch_model_1')\n",
    "TrainingMetrics.plot_classifier_loss_evolution(epochs_metrics, training_link_metrics, testing_link_metrics, 'Loss - classifier')\n",
    "TrainingMetrics.plot_edge_rate(epochs_metrics, training_link_metrics, testing_link_metrics, True)\n",
    "TrainingMetrics.plot_edge_rate(epochs_metrics,  training_link_metrics, testing_link_metrics, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59baaad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Show ROC curve and confusion matrices, for the latter you can decide the threshold cut used\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4e389",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Begin testing mode\n",
    "    branch_model.eval()\n",
    "    classifier_model.eval()\n",
    "    # Get predictions\n",
    "    pred_0_test = branch_model(torch.tensor(branch_model_input_test[0], dtype=torch.float))\n",
    "    pred_1_test = branch_model(torch.tensor(branch_model_input_test[1], dtype=torch.float))\n",
    "    classifier_pred_test = classifier_model(torch.concatenate((pred_0_test, pred_1_test), axis=1)).reshape(-1)\n",
    "\n",
    "    neg_scores_final_test = np.array(classifier_pred_test.tolist())[isTruePrimaryLink_test == 0].reshape(-1)\n",
    "    pos_scores_final_test = np.array(classifier_pred_test.tolist())[isTruePrimaryLink_test == 1].reshape(-1)\n",
    "    \n",
    "    TrainingMetrics.plot_roc_curve(torch.tensor(pos_scores_final_test), torch.tensor(neg_scores_final_test))\n",
    "    TrainingMetrics.draw_confusion_with_threshold(classifier_pred_test, isTruePrimaryLink_test, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b56014",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "   Save the model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847272c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_branch = torch.jit.script(branch_model)\n",
    "sm_branch.save(branchModelPath)\n",
    "\n",
    "sm_classifier = torch.jit.script(classifier_model)\n",
    "sm_classifier.save(classifierModelPath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
