{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Imports\n",
    "###########################################################\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.getcwd()[0:len(os.getcwd()) - 11])\n",
    "sys.path.insert(1, os.getcwd()[0:len(os.getcwd()) - 11] + '/Metrics')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import Models\n",
    "import TrainingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b068f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Define file\n",
    "###########################################################\n",
    "\n",
    "trainFileName = sys.path[0] + '/files/hierarchy_TRAIN_shower.npz'\n",
    "\n",
    "classifierModelPath = sys.path[0] + '/models/primary_shower_classifier_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Hyperparameters\n",
    "###########################################################\n",
    "\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Get data from file\n",
    "###########################################################\n",
    "\n",
    "data = np.load(trainFileName)\n",
    "\n",
    "# Variables\n",
    "variables_train = data['variables_train']\n",
    "variables_test = data['variables_test']\n",
    "# Training cut\n",
    "trainingCutDCA_train = data['trainingCutDCA_train']\n",
    "trainingCutDCA_test = data['trainingCutDCA_test']\n",
    "# Truth\n",
    "isTruePrimaryLink_train = data['isTruePrimaryLink_train']\n",
    "isTruePrimaryLink_test = data['isTruePrimaryLink_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b511a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Check shapes\n",
    "###########################################################\n",
    "\n",
    "print('variables_train.shape:', variables_train.shape)\n",
    "print('variables_test.shape:', variables_test.shape)\n",
    "print('trainingCutDCA_train.shape:', trainingCutDCA_train.shape)\n",
    "print('trainingCutDCA_test.shape:', trainingCutDCA_test.shape)\n",
    "print('isTruePrimaryLink_train.shape:', isTruePrimaryLink_train.shape)\n",
    "print('isTruePrimaryLink_test.shape:', isTruePrimaryLink_test.shape)\n",
    "\n",
    "nVariables = variables_train.shape[1]\n",
    "ntrain = variables_train.shape[0]\n",
    "ntest  = variables_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc794393",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Apply training cut topology mask\n",
    "###########################################################\n",
    "\n",
    "# These are inspired by hand-scanning :'(\n",
    "MAX_TRAINING_CUT_DCA = 50.0\n",
    "\n",
    "######################\n",
    "# training set first\n",
    "######################\n",
    "# Make mask\n",
    "passTrainingCutDCA_train = trainingCutDCA_train < MAX_TRAINING_CUT_DCA\n",
    "passTrainingCuts_train = passTrainingCutDCA_train\n",
    "\n",
    "# Mask the 1D variables... shape=(nEntries, )\n",
    "trainingCutDCA_train = trainingCutDCA_train[passTrainingCuts_train]\n",
    "isTruePrimaryLink_train = isTruePrimaryLink_train[passTrainingCuts_train]\n",
    "\n",
    "# Mask the variable... shape=(nEntries, nVariables)\n",
    "variables_train = variables_train[[[entry] * nVariables for entry in passTrainingCuts_train]].reshape(-1, nVariables)\n",
    "\n",
    "######################\n",
    "# now test set\n",
    "######################\n",
    "# Make mask\n",
    "passTrainingCutDCA_test = trainingCutDCA_test < MAX_TRAINING_CUT_DCA\n",
    "passTrainingCuts_test = passTrainingCutDCA_test\n",
    "\n",
    "# Mask the 1D variables... shape=(nEntries, )\n",
    "trainingCutDCA_test = trainingCutDCA_test[passTrainingCuts_test]\n",
    "isTruePrimaryLink_test = isTruePrimaryLink_test[passTrainingCuts_test]\n",
    "\n",
    "# Mask the variable... shape=(nEntries, nVariables)\n",
    "variables_test = variables_test[[[entry] * nVariables for entry in passTrainingCuts_test]].reshape(-1, nVariables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Check shapes\n",
    "###########################################################\n",
    "\n",
    "print('variables_train.shape:', variables_train.shape)\n",
    "print('variables_test.shape:', variables_test.shape)\n",
    "print('trainingCutDCA_train.shape:', trainingCutDCA_train.shape)\n",
    "print('trainingCutDCA_test.shape:', trainingCutDCA_test.shape)\n",
    "print('isTruePrimaryLink_train.shape:', isTruePrimaryLink_train.shape)\n",
    "print('isTruePrimaryLink_test.shape:', isTruePrimaryLink_test.shape)\n",
    "\n",
    "nVariables = variables_train.shape[1]\n",
    "ntrain = variables_train.shape[0]\n",
    "ntest  = variables_test.shape[0]\n",
    "\n",
    "print('')\n",
    "print('ntrain:', ntrain)\n",
    "print('ntest:', ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c151638",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Prepare Dataset objects\n",
    "###########################################################\n",
    "\n",
    "loader_train = DataLoader(list(zip(variables_train, isTruePrimaryLink_train)), shuffle=True, batch_size=BATCH_SIZE)\n",
    "loader_test = DataLoader(list(zip(variables_test, isTruePrimaryLink_test)), shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Define model and optimiser and compile the model\n",
    "###########################################################\n",
    "\n",
    "model = Models.PrimaryTrackShowerModel(nVariables, dropoutRate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Define class weights\n",
    "###########################################################\n",
    "\n",
    "nTrue_final = np.count_nonzero(isTruePrimaryLink_train == 1)\n",
    "nBackground_final = np.count_nonzero(isTruePrimaryLink_train == 0)\n",
    "\n",
    "maxLinks = max(nTrue_final, nBackground_final)\n",
    "\n",
    "classWeights_final = {0: maxLinks/nBackground_final, 1: maxLinks/nTrue_final}\n",
    "\n",
    "print('nTrue_final:', nTrue_final)\n",
    "print('nBackground_final:', nBackground_final)\n",
    "print('class weights:', classWeights_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cd5a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Training and testing\n",
    "######################\n",
    "\n",
    "# Optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "loss_func = torch.nn.BCELoss()\n",
    "#loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min', factor=0.1, patience=3, threshold=0.0001, threshold_mode='abs')\n",
    "\n",
    "# Put here some metrics\n",
    "training_epoch = []\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "training_positive_as_positive_rate = []\n",
    "training_positive_as_negative_rate = []\n",
    "training_negative_as_negative_rate = []\n",
    "training_negative_as_positive_rate = []\n",
    "\n",
    "testing_epoch = []\n",
    "testing_loss = []\n",
    "testing_accuracy = []\n",
    "testing_positive_as_positive_rate = []\n",
    "testing_positive_as_negative_rate = []\n",
    "testing_negative_as_negative_rate = []\n",
    "testing_negative_as_positive_rate = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    ######################\n",
    "    # Training \n",
    "    ######################\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Iterate in batches over the training dataset.                        \n",
    "    for inputs, targets in loader_train:  \n",
    "        \n",
    "        # Skip incomplete batches\n",
    "        if (inputs.shape[0] != BATCH_SIZE) :\n",
    "            continue        \n",
    "            \n",
    "        # Get predictions\n",
    "        pred = model(inputs).reshape(-1)\n",
    "\n",
    "        # Calc loss\n",
    "        weight = torch.ones(targets.shape)\n",
    "        weight[targets > 0.5] = classWeights_final[1]\n",
    "        weight[targets < 0.5] = classWeights_final[0]\n",
    "        loss_func.weight = weight\n",
    "        targets = targets.to(torch.float64)\n",
    "        pred = pred.type(torch.float64)\n",
    "        loss = loss_func(pred, targets)\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()   \n",
    "\n",
    "    # Update the scheduler\n",
    "    before_lr = optimiser.param_groups[0][\"lr\"]\n",
    "    scheduler.step(loss)\n",
    "    after_lr = optimiser.param_groups[0][\"lr\"]\n",
    "        \n",
    "    print(\"Epoch %d: SGD lr %.6f -> %.6f\" % (epoch, before_lr, after_lr))\n",
    "        \n",
    "    ######################\n",
    "    # Validation metrics \n",
    "    ######################\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Begin testing mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Initialise metrics        \n",
    "        total_batches_train = 0\n",
    "        total_loss_train = 0\n",
    "        pos_scores_train = []\n",
    "        neg_scores_train = []\n",
    "                \n",
    "        total_batches_test = 0\n",
    "        total_loss_test = 0\n",
    "        pos_scores_test = []\n",
    "        neg_scores_test = []\n",
    "                \n",
    "        # Iterate in batches over the training dataset.                        \n",
    "        for inputs_train, targets_train in loader_train:  \n",
    "\n",
    "            # Skip incomplete batches\n",
    "            if (inputs_train.shape[0] != BATCH_SIZE) :\n",
    "                continue        \n",
    "\n",
    "            # Get predictions\n",
    "            pred_train = model(inputs_train).reshape(-1)\n",
    "\n",
    "            # Calc loss\n",
    "            targets_train = targets_train.to(torch.float64)\n",
    "            pred_train = pred_train.type(torch.float64)\n",
    "            loss_train = loss_func(pred_train, targets_train)\n",
    "\n",
    "            # Add to our metrics\n",
    "            total_batches_train += 1\n",
    "            pos_scores_train.extend(np.array(pred_train.tolist())[targets_train > 0.5]) # they're not int, so IDK if == 1 works?\n",
    "            neg_scores_train.extend(np.array(pred_train.tolist())[targets_train < 0.5]) # they're not int, so IDK if == 1 works?\n",
    "            total_loss_train += loss_train.item()\n",
    "            \n",
    "        training_epoch.append(epoch)\n",
    "            \n",
    "        # Iterate in batches over the testing dataset.                        \n",
    "        for inputs_test, targets_test in loader_test:  \n",
    "\n",
    "            # Skip incomplete batches\n",
    "            if (inputs_test.shape[0] != BATCH_SIZE) :\n",
    "                continue        \n",
    "\n",
    "            # Get predictions\n",
    "            pred_test = model(inputs_test).reshape(-1)\n",
    "\n",
    "            # Calc loss\n",
    "            targets_test = targets_test.to(torch.float64)\n",
    "            pred_test = pred_test.type(torch.float64)\n",
    "            loss_test = loss_func(pred_test, targets_test)\n",
    "\n",
    "            # Add to our metrics\n",
    "            total_batches_test += 1\n",
    "            pos_scores_test.extend(np.array(pred_test.tolist())[targets_test > 0.5]) # they're not int, so IDK if == 1 works?\n",
    "            neg_scores_test.extend(np.array(pred_test.tolist())[targets_test < 0.5]) # they're not int, so IDK if == 1 works?\n",
    "            total_loss_test += loss_test.item()      \n",
    "            \n",
    "        testing_epoch.append(epoch)\n",
    "    \n",
    "    ##########################\n",
    "    # Calc metrics for epoch \n",
    "    ##########################   \n",
    "    # train\n",
    "    optimal_threshold_train, maximum_accuracy_train = TrainingMetrics.calculate_accuracy(torch.tensor(pos_scores_train), torch.tensor(neg_scores_train)) \n",
    "    # test\n",
    "    optimal_threshold_test, maximum_accuracy_test = TrainingMetrics.calculate_accuracy(torch.tensor(pos_scores_test), torch.tensor(neg_scores_test))\n",
    "\n",
    "    # train\n",
    "    positive_as_positive_train = np.count_nonzero(np.array(pos_scores_train) > optimal_threshold_train)\n",
    "    positive_as_negative_train = np.count_nonzero(np.array(pos_scores_train) < optimal_threshold_train)\n",
    "    negative_as_positive_train = np.count_nonzero(np.array(neg_scores_train) > optimal_threshold_train)\n",
    "    negative_as_negative_train = np.count_nonzero(np.array(neg_scores_train) < optimal_threshold_train)\n",
    "    # test\n",
    "    positive_as_positive_test = np.count_nonzero(np.array(pos_scores_test) > optimal_threshold_test)\n",
    "    positive_as_negative_test = np.count_nonzero(np.array(pos_scores_test) < optimal_threshold_test)\n",
    "    negative_as_positive_test = np.count_nonzero(np.array(neg_scores_test) > optimal_threshold_test)\n",
    "    negative_as_negative_test = np.count_nonzero(np.array(neg_scores_test) < optimal_threshold_test)\n",
    "    \n",
    "    # train\n",
    "    positive_as_positive_fraction_train = float(positive_as_positive_train) / float(positive_as_positive_train + positive_as_negative_train)\n",
    "    positive_as_negative_fraction_train = float(positive_as_negative_train) / float(positive_as_positive_train + positive_as_negative_train)\n",
    "    negative_as_positive_fraction_train = float(negative_as_positive_train) / float(negative_as_positive_train + negative_as_negative_train)\n",
    "    negative_as_negative_fraction_train = float(negative_as_negative_train) / float(negative_as_positive_train + negative_as_negative_train)\n",
    "    # test\n",
    "    positive_as_positive_fraction_test = float(positive_as_positive_test) / float(positive_as_positive_test + positive_as_negative_test)\n",
    "    positive_as_negative_fraction_test = float(positive_as_negative_test) / float(positive_as_positive_test + positive_as_negative_test)\n",
    "    negative_as_positive_fraction_test = float(negative_as_positive_test) / float(negative_as_positive_test + negative_as_negative_test)\n",
    "    negative_as_negative_fraction_test = float(negative_as_negative_test) / float(negative_as_positive_test + negative_as_negative_test)\n",
    "    \n",
    "    # train\n",
    "    training_loss.append(float(total_loss_train) / float(total_batches_train))\n",
    "    training_accuracy.append(maximum_accuracy_train)\n",
    "    training_positive_as_positive_rate.append(positive_as_positive_fraction_train)\n",
    "    training_positive_as_negative_rate.append(positive_as_negative_fraction_train)\n",
    "    training_negative_as_negative_rate.append(negative_as_negative_fraction_train)\n",
    "    training_negative_as_positive_rate.append(negative_as_positive_fraction_train)\n",
    "    # test\n",
    "    testing_loss.append(float(total_loss_test) / float(total_batches_test))\n",
    "    testing_accuracy.append(maximum_accuracy_test)\n",
    "    testing_positive_as_positive_rate.append(positive_as_positive_fraction_test)\n",
    "    testing_positive_as_negative_rate.append(positive_as_negative_fraction_test)\n",
    "    testing_negative_as_negative_rate.append(negative_as_negative_fraction_test)\n",
    "    testing_negative_as_positive_rate.append(negative_as_positive_fraction_test)\n",
    "\n",
    "    # Do some prints\n",
    "    print('----------------------------------------')\n",
    "    print('Epoch:', epoch)\n",
    "    print('----------------------------------------')\n",
    "    print('loss_train:', round(training_loss[-1], 2))\n",
    "    print('----')\n",
    "    print('optimal_threshold_train:', optimal_threshold_train)\n",
    "    print('accuracy_train:', str(round(maximum_accuracy_train.item(), 2)) +'%')\n",
    "    print('positive_as_positive_fraction_train:', str(round(positive_as_positive_fraction_train * 100.0, 2)) + '%')\n",
    "    print('positive_as_negative_fraction_train:', str(round(positive_as_negative_fraction_train * 100.0, 2)) + '%')\n",
    "    print('negative_as_negative_fraction_train:', str(round(negative_as_negative_fraction_train * 100.0, 2)) + '%')\n",
    "    print('negative_as_positive_fraction_train:', str(round(negative_as_positive_fraction_train * 100.0, 2)) + '%')\n",
    "    print('----')\n",
    "    print('loss_test:', round(testing_loss[-1], 2))\n",
    "    print('----')\n",
    "    print('optimal_threshold_test:', optimal_threshold_test)\n",
    "    print('accuracy_test:', str(round(maximum_accuracy_test.item(), 2)) +'%')\n",
    "    print('positive_as_positive_fraction_test:', str(round(positive_as_positive_fraction_test * 100.0, 2)) + '%')\n",
    "    print('positive_as_negative_fraction_test:', str(round(positive_as_negative_fraction_test * 100.0, 2)) + '%')\n",
    "    print('negative_as_negative_fraction_test:', str(round(negative_as_negative_fraction_test * 100.0, 2)) + '%')\n",
    "    print('negative_as_positive_fraction_test:', str(round(negative_as_positive_fraction_test * 100.0, 2)) + '%')\n",
    "    print('----')\n",
    "    TrainingMetrics.plot_scores_classifier(pos_scores_train, neg_scores_train, pos_scores_test, neg_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18015950",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print metrics showing evolution   \n",
    "TrainingMetrics.plot_loss_evolution(training_epoch, training_loss, testing_loss, 'Classifier')\n",
    "TrainingMetrics.plot_edge_rate(training_epoch, training_positive_as_positive_rate, training_positive_as_negative_rate, testing_positive_as_positive_rate, testing_positive_as_negative_rate, True)\n",
    "TrainingMetrics.plot_edge_rate(testing_epoch, training_negative_as_negative_rate, training_negative_as_positive_rate, testing_negative_as_negative_rate, testing_negative_as_positive_rate, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7269cc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Confusion matrices!\n",
    "######################\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Begin testing mode\n",
    "    model.eval()\n",
    "    \n",
    "    pred_final_test = model(torch.tensor(variables_test))\n",
    "    \n",
    "    pos_scores_final_test = np.array(pred_final_test.tolist())[isTruePrimaryLink_test > 0.5] # they're not int, so IDK if == 1 works?\n",
    "    neg_scores_final_test = np.array(pred_final_test.tolist())[isTruePrimaryLink_test < 0.5] # they're not int, so IDK if == 1 works?\n",
    "    \n",
    "    TrainingMetrics.plot_roc_curve(torch.tensor(pos_scores_final_test), torch.tensor(neg_scores_final_test))\n",
    "    TrainingMetrics.draw_confusion_with_threshold(pred_final_test, isTruePrimaryLink_test, 0.5)\n",
    "    TrainingMetrics.draw_confusion_with_threshold(pred_final_test, isTruePrimaryLink_test, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Save the model\n",
    "###################### \n",
    "\n",
    "sm = torch.jit.script(model)\n",
    "sm.save(classifierModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2e1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead98148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
