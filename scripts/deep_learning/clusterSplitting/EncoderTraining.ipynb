{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8766f66-e5f0-451e-a348-5ee21a0c7090",
   "metadata": {},
   "source": [
    "## Encoder Training\n",
    "\n",
    "written by Isobel Mawby (i.mawby1@lancaster.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b68067-c6f6-4c2a-85bb-b880e85fd842",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Imports\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d59007a-45d9-4ab7-90a4-904a3f9f6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import Datasets\n",
    "import TrainingMetrics\n",
    "import Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09664323-f8e6-47f2-bfcc-4b8308d2578e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Set device\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4536d-2b71-4cb3-8a29-6ae557173270",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee8deb-7df7-4f5e-a200-4111c445c85e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Config\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c17221-986a-4a34-be88-dc78af6384a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FRACTION = 0.75\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887f789-59a4-47a0-b048-492b82a5db24",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    File \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08366804-5c02-4760-9350-6e3bac5d784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = sys.path[0] + '/files/ContaminationClassifierModel_UVW'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed25b8-f45f-4f80-9a8c-433ab5aae46f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Pull out things from file\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e64ea-9e72-4e4a-aa8b-8f7c6700fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = Datasets.get_classification_datasets(device, TRAINING_FRACTION)\n",
    "\n",
    "print('Input(train):', train_dataset.input.shape)\n",
    "print('Truth(train):', train_dataset.labels.shape)\n",
    "print('')\n",
    "print('Input(test):', test_dataset.input.shape)\n",
    "print('Truth(test):', test_dataset.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e49425-fd66-46ac-9b83-a4a19740cf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0, generator=torch.Generator(device='cpu'))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=0, generator=torch.Generator(device='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692cb397-6677-4ab4-bc45-2ba853b4b695",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Class Weights\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9222a76-bea9-4187-a139-5261b8eddd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nFalse = torch.count_nonzero(train_dataset.labels == 0).item()\n",
    "nTrue = torch.count_nonzero(train_dataset.labels == 1).item()\n",
    "nShower = torch.count_nonzero(train_dataset.labels == 2).item()\n",
    "maxLinks = max(nTrue, nFalse, nShower)\n",
    "\n",
    "class_weights = torch.tensor([float(maxLinks)/float(nFalse), float(maxLinks)/float(nTrue), float(maxLinks)/float(nShower)])\n",
    "\n",
    "print('nShower:', nShower)\n",
    "print('nTrue:', nTrue)\n",
    "print('nFalse:', nFalse)\n",
    "print('weights:', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72efb7-3f25-4b67-98c5-c6784c8e628b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Setup training\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbdafa-1291-4bfd-a574-d5448432bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our model\n",
    "_, _, n_features = train_dataset.input.shape\n",
    "model = Models.ConvModel(device, num_features=n_features)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimiser = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimiser, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72838f24-7558-4b2f-904c-01eafa5ceca0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Let's start training!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809630c0-f9b6-4036-9b6e-7fabe0f22593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_function(pred, targets, class_weights) :\n",
    "    # Loss function\n",
    "    loss_func = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    # Calc loss \n",
    "    loss = loss_func(pred, targets)\n",
    "    # Apply weighting\n",
    "    loss[targets == 0] *= class_weights[0]\n",
    "    loss[targets == 1] *= class_weights[1]\n",
    "    loss[targets == 2] *= class_weights[2]\n",
    "    loss = (loss.sum() / loss.shape[0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669c85f-4226-40f5-b7fd-807e31d1dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize progress bar for tracking epochs\n",
    "pbar = trange(0, N_EPOCHS, leave=True, desc=\"Epoch\")\n",
    "\n",
    "# Loggers for training and testing\n",
    "training_av_loss_logger = []\n",
    "test_av_loss_logger = []\n",
    "training_acc_logger = []\n",
    "test_acc_logger = []\n",
    "train_false = []\n",
    "train_true = []\n",
    "train_shower = []\n",
    "test_false = []\n",
    "test_true = []\n",
    "test_shower = []\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in pbar:\n",
    "    \n",
    "    # Metrics\n",
    "    train_loss_count = 0.0   \n",
    "    n_pred_false_train, n_pred_true_train, n_pred_shower_train = 0, 0, 0\n",
    "    n_false_train, n_true_train, n_shower_train = 0, 0, 0\n",
    "    test_loss_count = 0.0\n",
    "    n_pred_false_test, n_pred_true_test, n_pred_shower_test = 0, 0, 0\n",
    "    n_false_test, n_true_test, n_shower_test = 0, 0, 0    \n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Loop over each batch in the training dataset\n",
    "    for x_train, label_train in tqdm(train_dataloader, desc=\"Training\", leave=True):\n",
    "        \n",
    "        # Get the model predictions\n",
    "        pred = model(x_train)\n",
    "        \n",
    "        # Compute the loss using cross-entropy loss\n",
    "        label_train = label_train.squeeze(1)\n",
    "        loss = loss_function(pred, label_train, class_weights)\n",
    "        \n",
    "        # Backpropagation and optimization step\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    tt = time.time()\n",
    "    print(f'Training Time: {tt-t0:.3f} s')\n",
    "    \n",
    "    # Update learning rate\n",
    "    before_lr = optimiser.param_groups[0][\"lr\"]\n",
    "    scheduler.step()\n",
    "    after_lr = optimiser.param_groups[0][\"lr\"]\n",
    "    print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))      \n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        # Loop over each batch in the training dataset\n",
    "        for x_train, label_train in tqdm(train_dataloader, desc=\"Validation(Train)\", leave=True):\n",
    "            \n",
    "            # Get the model predictions\n",
    "            pred = model(x_train)\n",
    "\n",
    "            # Compute the loss using cross-entropy loss\n",
    "            label_train = label_train.squeeze(1)\n",
    "            loss = loss_function(pred, label_train, class_weights)\n",
    "            train_loss_count += loss.item()\n",
    "\n",
    "            # Apply sigmoid for inference\n",
    "            pred = torch.softmax(pred, dim=1)           \n",
    "            \n",
    "            # Update training accuracy\n",
    "            n_pred_false_train += (torch.argmax(pred, dim=1)[label_train == 0] == 0).sum().item()\n",
    "            n_pred_true_train += (torch.argmax(pred, dim=1)[label_train == 1] == 1).sum().item()\n",
    "            n_pred_shower_train += (torch.argmax(pred, dim=1)[label_train == 2] == 2).sum().item()\n",
    "            n_false_train += (label_train == 0).sum().item()\n",
    "            n_true_train += (label_train == 1).sum().item()\n",
    "            n_shower_train += (label_train == 2).sum().item() \n",
    "    \n",
    "        # Loop over each batch in the testing dataset\n",
    "        for x_test, label_test in tqdm(test_dataloader, desc=\"Validation(Test)\", leave=True):\n",
    "\n",
    "            # Get the model predictions\n",
    "            pred = model(x_test)\n",
    "            \n",
    "            # Compute the loss using cross-entropy loss\n",
    "            label_test = label_test.squeeze(1)\n",
    "            loss = loss_function(pred, label_test, class_weights)\n",
    "            test_loss_count += loss.item()\n",
    "            \n",
    "            # Apply sigmoid for inference\n",
    "            pred = torch.softmax(pred, dim=1)                     \n",
    "\n",
    "            # Update testing accuracy\n",
    "            n_pred_false_test += (torch.argmax(pred, dim=1)[label_test == 0] == 0).sum().item()\n",
    "            n_pred_true_test += (torch.argmax(pred, dim=1)[label_test == 1] == 1).sum().item()\n",
    "            n_pred_shower_test += (torch.argmax(pred, dim=1)[label_test == 2] == 2).sum().item()\n",
    "            n_false_test += (label_test == 0).sum().item()\n",
    "            n_true_test += (label_test == 1).sum().item()\n",
    "            n_shower_test += (label_test == 2).sum().item()   \n",
    "\n",
    "        tv = time.time()\n",
    "        print(f'Validation Time: {tv-tt:.3f} s')\n",
    "\n",
    "        # Record values\n",
    "        false_eff_train = round(float(n_pred_false_train)/ n_false_train * 100.0, 2)\n",
    "        false_eff_test = round(float(n_pred_false_test)/ n_false_test * 100.0, 2)\n",
    "        true_eff_train = round(float(n_pred_true_train)/ n_true_train * 100.0, 2)\n",
    "        true_eff_test = round(float(n_pred_true_test)/ n_true_test * 100.0, 2)\n",
    "        shower_eff_train = round(float(n_pred_shower_train)/ n_shower_train * 100.0, 2)\n",
    "        shower_eff_test = round(float(n_pred_shower_test)/ n_shower_test * 100.0, 2)\n",
    "        train_false.append(false_eff_train)\n",
    "        train_true.append(true_eff_train)\n",
    "        train_shower.append(shower_eff_train)\n",
    "        test_false.append(false_eff_test)\n",
    "        test_true.append(true_eff_test)\n",
    "        test_shower.append(shower_eff_test)        \n",
    "        training_av_loss_logger.append(train_loss_count / len(training_dataloader))\n",
    "        test_av_loss_logger.append(test_loss_count / len(validation_dataloader))\n",
    "\n",
    "        # Do prints for epoch\n",
    "        print(f'False efficiency: {round(float(n_pred_false_train)/ n_false_train * 100.0, 2)}% (train), {round(float(n_pred_false_test)/ n_false_test * 100.0, 2)}% (train)')\n",
    "        print(f'True efficiency: {round(float(n_pred_true_train)/ n_true_train * 100.0, 2)}% (train), {round(float(n_pred_true_test)/ n_true_test * 100.0, 2)}% (train)')\n",
    "        print(f'Shower efficiency: {round(float(n_pred_shower_train)/ n_shower_train * 100.0, 2)}% (train), {round(float(n_pred_shower_test)/ n_shower_test * 100.0, 2)}% (train)')        \n",
    "        \n",
    "        # Save model\n",
    "        model_cpu = model.to('cpu').eval()\n",
    "        sm = torch.jit.script(model_cpu)\n",
    "        sm.save(f\"{modelPath}_{epoch}.pt\")\n",
    "        torch.save(model_cpu.state_dict(), f\"{modelPath}_{epoch}.pkl\")\n",
    "        model = model.to(device)\n",
    "        print(f\"Saved model at epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59425a-7cab-452e-9787-ee2d0e28d9f6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size: 18px;\">\n",
    "    Made some post-training performance plots\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14521df4-2748-4feb-b641-ce9355bb2dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(range(1, N_EPOCHS + 1), training_av_loss_logger)\n",
    "_ = plt.plot(range(1, N_EPOCHS + 1), test_av_loss_logger)\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "_ = plt.title(\"Training Vs Test Av. Loss\")\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fefd1d-5765-42e3-856f-d29265b13ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(range(1, N_EPOCHS + 1), training_acc_logger)\n",
    "_ = plt.plot(range(1, N_EPOCHS + 1), test_acc_logger)\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "_ = plt.title(\"Training Vs Test Accuracy\")\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Accuracy\")\n",
    "print(\"Max Test Accuracy %.2f%%\" % (np.max(test_acc_logger) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
